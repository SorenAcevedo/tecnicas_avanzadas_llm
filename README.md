# RAG Knowledge System: Arquitectura Escalable para Chatbot Empresarial

## ðŸ‘¥ Integrantes del grupo

- Juan Jose Bonilla - 22502052
- Yan Carlos Cuaran Imbacuan - 22502591
- Nicolas Lozano Mazuera - 22500565
- Soren Acevedo - 22500566

## ðŸ­ Componentes Principales


### 1. **Scraping Engine** (Selenium, Requests, BeautifulSoup)

- **CaracterÃ­sticas**:
  - ExtracciÃ³n de datos web usando Selenium para navegaciÃ³n y Requests para descargas directas
  - Parsing y limpieza bÃ¡sica con BeautifulSoup
  - No se implementÃ³ rotaciÃ³n de proxies, user agents ni manejo avanzado de rate limiting


### 2. **Data Processing Pipeline**

- **Procesamiento realizado:**
  - ConversiÃ³n de datos extraÃ­dos a archivos de texto plano
  - No se han implementado estrategias de chunking, segmentaciÃ³n semÃ¡ntica ni procesamiento avanzado


### 3. **Vector Database Layer**

- **No implementado aÃºn.**

### 4. **RAG Implementation** (LangChain Framework)

- **No implementado aÃºn.**


### 5. **LLM Abstraction Layer**

- **Providers Soportados**:
  - **Ollama**
  - **OpenAI**
  - **Gemini**

- **ImplementaciÃ³n actual:**
  - AbstracciÃ³n de proveedores en `src/chatbot/providers/`.
  - SelecciÃ³n de modelo y proveedor desde la interfaz.


### 6. **Monitoring & Observability**

- **Logging**: Implementado en `src/core/logging/logger.py`.
- **Metrics, Tracing, Health Checks**: No implementados aÃºn.


## ðŸ”§ TecnologÃ­as y Justificaciones

| Componente        | TecnologÃ­a                  | JustificaciÃ³n                                                                      |
| ----------------- | --------------------------- | ---------------------------------------------------------------------------------- |
| Web Scraping      | **Selenium, Requests, BeautifulSoup** | Herramientas estÃ¡ndar para scraping y parsing en Python                            |
| Text Processing   | **Python estÃ¡ndar**         | ConversiÃ³n bÃ¡sica a texto plano                                                    |
| Vector Embeddings | **No implementado**         |                                                                                   |
| Vector Database   | **No implementado**         |                                                                                   |
| RAG Framework     | **No implementado**         |                                                                                   |
| API Framework     | **No implementado**         |                                                                                   |
| UI Framework      | **Streamlit**               | Prototipado rÃ¡pido para interfaces de ML/AI [9]                                    |
| Containerization  | **No implementado**         |                                                                                   |
| Queue System      | **No implementado**         |                                                                                   |


## ðŸ“ Estructura del Proyecto (actual)

```
â”œâ”€â”€ app.py
â”œâ”€â”€ LICENSE
â”œâ”€â”€ Makefile
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ README.md
â”œâ”€â”€ config/
â”‚   â””â”€â”€ models.yaml
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ embeddings/
â”‚   â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ processed/
â”‚   â”‚   â”œâ”€â”€ context_colgate.txt
â”‚   â”‚   â”œâ”€â”€ context_palmolive.txt
â”‚   â”‚   â”œâ”€â”€ context_youtube.txt
â”‚   â”‚   â”œâ”€â”€ company_context.txt
â”‚   â”œâ”€â”€ raw/
â”‚   â”‚   â”œâ”€â”€ company_data.json
â”‚   â”‚   â”œâ”€â”€ productos_colgate.csv
â”‚   â”‚   â”œâ”€â”€ productos_palmolive.csv
â”‚   â”‚   â””â”€â”€ youtube_channel_videos.json
â”‚   â””â”€â”€ qa/
â”‚       â””â”€â”€ qa_colgate_palmolive.csv
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ chatbot/
â”‚   â”‚   â”œâ”€â”€ providers/
â”‚   â”‚   â”‚   â”œâ”€â”€ base.py
â”‚   â”‚   â”‚   â”œâ”€â”€ gemini.py
â”‚   â”‚   â”‚   â”œâ”€â”€ ollama.py
â”‚   â”‚   â”‚   â””â”€â”€ openai.py
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ prompts.py
â”‚   â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”‚   â”œâ”€â”€ model_loader.py
â”‚   â”‚   â”‚   â””â”€â”€ settings.py
â”‚   â”‚   â”œâ”€â”€ logging/
â”‚   â”‚   â”‚   â””â”€â”€ logger.py
â”‚   â”œâ”€â”€ langchain/
â”‚   â”‚   â”œâ”€â”€ contexto.txt
â”‚   â”‚   â””â”€â”€ ollama_test.py
â”‚   â”œâ”€â”€ processing/
â”‚   â”‚   â”œâ”€â”€ chunking.py
â”‚   â”‚   â”œâ”€â”€ plain_company_processing.py
â”‚   â”‚   â”œâ”€â”€ plain_products_processing.py
â”‚   â”‚   â”œâ”€â”€ plain_youtube_processing.py
â”‚   â”‚   â””â”€â”€ preprocessing.py
â”‚   â”œâ”€â”€ scraping/
â”‚   â”‚   â”œâ”€â”€ colgate_palmolive.py
â”‚   â”‚   â”œâ”€â”€ colgate_productos.py
â”‚   â”‚   â”œâ”€â”€ fetch_social_media.py
â”‚   â”‚   â””â”€â”€ palmolive_productos.py
â”‚   â”‚   â””â”€â”€ driver/
â””â”€â”€ ...
```

## ðŸš€ Pipeline de Datos

### MÃ³dulo 1: Pipeline sin chunking, embedding, vector db, tag

```mermaid
flowchart LR
  A[Web Scraping] --> B[Raw Data Storage]
  B --> C[Data Cleaning & Preprocessing]
  C --> D[Response Generation]
  D --> E[Chatbot Interface]
```

### MÃ³dulo 2: Pipeline con chunking, embedding, vector db, tag

```mermaid
flowchart LR
  A[Web Scraping] --> B[Raw Data Storage]
  B --> C[Data Cleaning & Preprocessing]
  C --> D[Text Chunking]
  D --> E[Embedding Generation]
  E --> F[Vector Database Storage]
  F --> G[Tagging]
  G --> H[RAG Retrieval System]
  H --> I[LLM Processing]
  I --> J[Response Generation]
  J --> K[Chatbot Interface]
```

## ðŸ“‹ InstalaciÃ³n y ConfiguraciÃ³n

### Pre-requisitos

- Python 3.9+ (se recomienda 3.11)
- [uv](https://github.com/astral-sh/uv) - Gestor de paquetes ultrarrÃ¡pido
- Docker y Docker Compose
- Make
- Git




### Comandos Principales

```bash
# Ejecutar la aplicaciÃ³n Streamlit
make start                # Inicia la interfaz Streamlit en http://localhost:8501

# Scraping de productos
make scrape-palmolive     # Scrapea productos Palmolive
make scrape-colgate       # Scrapea productos Colgate
make scrape-all           # Scrapea ambos productos

# Preprocesamiento a texto plano
make txt-products-preprocess   # Convierte productos a texto plano
make txt-youtube-preprocess    # Convierte datos de YouTube a texto plano
make txt-company-preprocess    # Convierte datos de empresa a texto plano
make txt-preprocess            # Ejecuta todos los preprocesamientos a texto plano

# Preprocesamiento general
make preprocess           # Preprocesa todos los datos

# Chunking (experimental)
make chunk                # Aplica chunking a los textos
```


## ðŸ“š Referencias

- Selenium Documentation. (2025). "Selenium WebDriver for browser automation." https://www.selenium.dev/
- Requests Documentation. (2025). "Requests: HTTP for Humans." https://docs.python-requests.org/
- BeautifulSoup Documentation. (2025). "Beautiful Soup: HTML/XML parsing library." https://www.crummy.com/software/BeautifulSoup/bs4/doc/
- Streamlit Documentation. (2025). "Streamlit: The fastest way to build and share data apps." https://streamlit.io/

## ðŸ“„ Licencia

MIT License - Ver archivo LICENSE para mÃ¡s detalles.

---
